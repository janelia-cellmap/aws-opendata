## Introduction to COSEM
The [COSEM](https://www.janelia.org/project-team/cosem) (Cellular Organelle Segmentation in Electron Microscopy) project team at Janelia Research campus uses computer vision techniques to scalably detect subcellular structures in datasets generated with next-generation volumetric electron microscopy.  

COSEM processes datasets that are acquired by members of the [Hess lab](https://www.janelia.org/lab/hess-lab) at Janelia Research Campus using Focused Ion Beam - Scanning Electron Microscopy (FIB-SEM). FIB-SEM is an electron microscopy technique that enables volumetric imaging of single cells and / or bulk tissue at nanometer isotropic resolution. For more information about FIB-SEM microscopy and its applications, see these publications: [Xu et al.](https://elifesciences.org/articles/25916), [Hoffman et al.](https://science.sciencemag.org/content/367/6475/eaaz5357). 

FIB-SEM datasets are large (hundreds of gigabytes), dense, and extremely detailed, which poses a challenge for image processing routines. COSEM develops machine learning tools that segment features of interest -- ribosomes, mitochondria, the endoplasmic reticulum, and other organelles -- from FIB-SEM datasets. The segmented organelles form a semantic layer on top of the raw FIB-SEM data that biologists can use to answer basic questions about how cells are organized. 

## Cloud-hosted datasets
Each FIBSEM dataset is stored on [Amazon Web Services](https://aws.amazon.com/) object storage service [S3](https://aws.amazon.com/s3/)  using the chunked hierarchical array container format [N5](https://github.com/saalfeldlab/n5). Access to N5 containers is supported in the [Java](https://github.com/saalfeldlab/n5), [Python](https://github.com/constantinpape/z5), and [Rust](https://github.com/aschampion/rust-n5) programming languages. 

For each dataset we provide some or all of the following sources of data:
* FIB-SEM data: A 3D FIB-SEM volume that has been aligned and minimally preprocessed.  

* Ground-truth: Regions of the raw FIB-SEM volume wherein every voxel has been labelled by a human annotator. These annotations are used to train machine learning models. There are typically many ground-truth volumes per FIB-SEM dataset. Within each volume, voxels are assigned a class such as Endoplasmic Reticulum (ER), Mitochondira (mito), Plasma Membrane (PM), etc.

* Predictions: A collection of 3D volumes (one per label), each of which is a putative segmentation of the FIB-SEM data for a particular object class. These volumes are generated by machine learning models trained on the ground truth data described above.

* As our methods improve we will likely add additional forms of derived data, e.g. mesh representations of segmented organelles.

The following diagram illustrates how volumetric array data are organized within the n5 container. To facilitate visualization, each volume type (.e.g, raw FIB-SEM data) is saved at multiple resolutions; `s0` is the highest resoltuion, `s1` is half resolution, and so on.

```bash
.
├── cell0.n5
│   ├── README.md # description of the dataset
│   ├── fibsem # raw fibsem data
│   │   ├── s0 # 3D array of uint8, full resolution
│   │   ├── s1 # 3D array of uint8, half resolution
│   │   ┊
│   │
│   ├── ground_truth # sparse annotated regions of interest
│   │   ├── s0 # 3D array of uint8, full resolution
│   │   ├── s1 # 3D array of uint8, half resolution
│   │   ┊
│   │
│   ├── predictions # ML-generated segmentations
│   │   ├── mito
│   │   │   ├── s0 # 3D array of uint8, full resolution
│   │   │   ├── s1 # 3D array of uint8, half resolution
│   │   │   ┊
│   │   │   
│   │   ├── er
│   │   │   ├── s0 # 3D array of uint8, full resolution
│   │   │   ├── s1 # 3D array of uint8, half resolution
│   │   │   ┊
│   │   │
│   │   ├── pm
│   │   │   ├── s0 # 3D array of uint8, full resolution
│   │   │   ├── s1 # 3D array of uint8, half resolution
│   │   │   ┊ 
┊   ┊   ┊   ┊

```

## Visualization
We recommend the following visualization tools for exploring the data: 
* [Neuroglancer](https://github.com/google/neuroglancer). This is a browser-based tool for visualizing large volumetric datasets that supports cloud-hosted data in the n5 format.
* The `n5-view` command in [n5-utils](https://github.com/saalfeldlab/n5-utils). This is a Java application that allows viewing large volumetric datasets stored in n5 format from the local filesystem.

